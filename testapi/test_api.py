#!/usr/bin/env python3
"""
Qwen3-VL API æµ‹è¯•è„šæœ¬

æµ‹è¯• vLLM OpenAI å…¼å®¹ API çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. å¥åº·æ£€æŸ¥
2. æ¨¡å‹åˆ—è¡¨
3. æ–‡æœ¬æ¨ç†
4. å›¾åƒ+æ–‡æœ¬æ¨ç†
"""

import base64
import io
import json
import sys
from pathlib import Path

import requests


def _ensure_utf8_stdio() -> None:
    for stream_name in ("stdout", "stderr"):
        stream = getattr(sys, stream_name, None)
        if stream is None:
            continue

        try:
            stream.reconfigure(encoding="utf-8", errors="replace")
            continue
        except Exception:
            pass

        try:
            buffer = getattr(stream, "buffer", None)
            if buffer is not None:
                wrapped = io.TextIOWrapper(
                    buffer,
                    encoding="utf-8",
                    errors="replace",
                    line_buffering=True,
                )
                setattr(sys, stream_name, wrapped)
        except Exception:
            pass


_ensure_utf8_stdio()


class Qwen3VLTester:
    """Qwen3-VL API æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:20000"):
        self.base_url = base_url.rstrip("/")
        self.headers = {"Content-Type": "application/json"}

    def test_health(self) -> bool:
        """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        print("\n" + "=" * 50)
        print("æµ‹è¯• 1: å¥åº·æ£€æŸ¥")
        print("=" * 50)

        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            print(f"çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”: {response.text}")

            if response.status_code == 200:
                print("âœ“ å¥åº·æ£€æŸ¥é€šè¿‡")
                return True
            else:
                print("âœ— å¥åº·æ£€æŸ¥å¤±è´¥")
                return False
        except Exception as e:
            print(f"âœ— è¯·æ±‚å¤±è´¥: {e}")
            return False

    def test_models(self) -> bool:
        """æµ‹è¯•æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹"""
        print("\n" + "=" * 50)
        print("æµ‹è¯• 2: æ¨¡å‹åˆ—è¡¨")
        print("=" * 50)

        try:
            response = requests.get(f"{self.base_url}/v1/models", timeout=5)
            print(f"çŠ¶æ€ç : {response.status_code}")

            if response.status_code == 200:
                data = response.json()
                print(f"å¯ç”¨æ¨¡å‹æ•°é‡: {len(data.get('data', []))}")
                for model in data.get("data", []):
                    print(f"  - {model.get('id')}")
                print("âœ“ æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸ")
                return True
            else:
                print(f"âœ— è·å–å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âœ— è¯·æ±‚å¤±è´¥: {e}")
            return False

    def test_text_inference(self) -> bool:
        """æµ‹è¯•æ–‡æœ¬æ¨ç†"""
        print("\n" + "=" * 50)
        print("æµ‹è¯• 3: æ–‡æœ¬æ¨ç†")
        print("=" * 50)

        payload = {
            "model": "Qwen3-VL-32B-Instruct",
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ],
            "max_tokens": 100,
            "temperature": 0.7,
        }

        print(f"è¯·æ±‚: {json.dumps(payload, ensure_ascii=False, indent=2)}")

        try:
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30,
            )
            print(f"\nçŠ¶æ€ç : {response.status_code}")

            if response.status_code == 200:
                data = response.json()
                content = data["choices"][0]["message"]["content"]
                print(f"\næ¨¡å‹å›å¤:\n{content}")
                print(f"\nToken ä½¿ç”¨: {data.get('usage', {})}")
                print("âœ“ æ–‡æœ¬æ¨ç†æˆåŠŸ")
                return True
            else:
                print(f"âœ— æ¨ç†å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âœ— è¯·æ±‚å¤±è´¥: {e}")
            return False

    def test_image_inference(self, image_path: str = None) -> bool:
        """æµ‹è¯•å›¾åƒ+æ–‡æœ¬æ¨ç†"""
        print("\n" + "=" * 50)
        print("æµ‹è¯• 4: å›¾åƒ+æ–‡æœ¬æ¨ç†")
        print("=" * 50)

        # å¦‚æœæ²¡æœ‰æä¾›å›¾åƒï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒï¼ˆ1x1 çº¢è‰²åƒç´ ï¼‰
        if image_path is None:
            print("æœªæä¾›æµ‹è¯•å›¾åƒï¼Œè·³è¿‡æ­¤æµ‹è¯•")
            print("æç¤º: è¿è¡Œ python testapi/test_api.py --image <å›¾åƒè·¯å¾„> æ¥æµ‹è¯•å›¾åƒæ¨ç†")
            return True

        # è¯»å–å¹¶ç¼–ç å›¾åƒ
        try:
            with open(image_path, "rb") as f:
                image_data = f.read()
            image_base64 = base64.b64encode(image_data).decode("utf-8")
            print(f"å›¾åƒè·¯å¾„: {image_path}")
            print(f"å›¾åƒå¤§å°: {len(image_data)} å­—èŠ‚")
        except Exception as e:
            print(f"âœ— è¯»å–å›¾åƒå¤±è´¥: {e}")
            return False

        payload = {
            "model": "Qwen3-VL-32B-Instruct",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            },
                        },
                        {"type": "text", "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"},
                    ],
                }
            ],
            "max_tokens": 500,
            "temperature": 0.7,
        }

        print("å‘é€å›¾åƒæ¨ç†è¯·æ±‚...")

        try:
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=60,
            )
            print(f"\nçŠ¶æ€ç : {response.status_code}")

            if response.status_code == 200:
                data = response.json()
                content = data["choices"][0]["message"]["content"]
                print(f"\næ¨¡å‹å›å¤:\n{content}")
                print(f"\nToken ä½¿ç”¨: {data.get('usage', {})}")
                print("âœ“ å›¾åƒæ¨ç†æˆåŠŸ")
                return True
            else:
                print(f"âœ— æ¨ç†å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âœ— è¯·æ±‚å¤±è´¥: {e}")
            return False

    def run_all_tests(self, image_path: str = None):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n" + "=" * 50)
        print("Qwen3-VL API æµ‹è¯•å¥—ä»¶")
        print(f"æœåŠ¡åœ°å€: {self.base_url}")
        print("=" * 50)

        results = {
            "å¥åº·æ£€æŸ¥": self.test_health(),
            "æ¨¡å‹åˆ—è¡¨": self.test_models(),
            "æ–‡æœ¬æ¨ç†": self.test_text_inference(),
            "å›¾åƒæ¨ç†": self.test_image_inference(image_path),
        }

        # æ‰“å°æµ‹è¯•æ€»ç»“
        print("\n" + "=" * 50)
        print("æµ‹è¯•æ€»ç»“")
        print("=" * 50)

        passed = sum(results.values())
        total = len(results)

        for test_name, result in results.items():
            status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
            print(f"{test_name}: {status}")

        print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

        if passed == total:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            return 0
        else:
            print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
            return 1


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Qwen3-VL API æµ‹è¯•è„šæœ¬")
    parser.add_argument(
        "--url",
        default="http://localhost:20000",
        help="API æœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:20000)",
    )
    parser.add_argument("--image", help="æµ‹è¯•å›¾åƒè·¯å¾„ï¼ˆç”¨äºå›¾åƒæ¨ç†æµ‹è¯•ï¼‰")

    args = parser.parse_args()

    tester = Qwen3VLTester(base_url=args.url)
    exit_code = tester.run_all_tests(image_path=args.image)
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
