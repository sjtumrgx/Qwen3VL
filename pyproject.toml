[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "qwen3vl-inference"
version = "0.1.0"
description = "基于 LMDeploy 的 Qwen3-VL-32B-Instruct 推理服务（FastAPI 适配层）"
readme = "README.md"
requires-python = ">=3.10"
license = { text = "MIT" }
dependencies = [
  "transformers==4.57.6",
  "fastapi>=0.100.0",
  "uvicorn[standard]>=0.23.0",
  "python-multipart>=0.0.6",
  "Pillow>=10.0.0",
  "pydantic>=2.0.0",
  "requests>=2.31.0",
  "opencv-python-headless>=4.8.0",
  "numpy>=1.24.0",
  "websockets>=11.0.0",
]

[project.optional-dependencies]
inference = [
  "lmdeploy==0.11.1",
  "triton==3.1.0",
]
modeldownload = ["modelscope"]

[tool.setuptools.packages.find]
where = ["."]
include = ["app*"]
